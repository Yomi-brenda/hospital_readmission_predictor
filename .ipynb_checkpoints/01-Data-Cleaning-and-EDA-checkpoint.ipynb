{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03268b80-8316-40b9-937f-38511db81be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "\n",
      "Dataset shape: (101766, 50)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/diabetic_data.csv')\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Get a concise summary of the dataframe\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Check the dimensions of the dataset\n",
    "print(f\"\\nDataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b335dafd-662b-46b7-8a2c-a5beb508ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in each column:\n",
      "weight                      96.858479\n",
      "max_glu_serum               94.746772\n",
      "A1Cresult                   83.277322\n",
      "medical_specialty           49.082208\n",
      "payer_code                  39.557416\n",
      "race                         2.233555\n",
      "diag_3                       1.398306\n",
      "diag_2                       0.351787\n",
      "diag_1                       0.020636\n",
      "patient_nbr                  0.000000\n",
      "time_in_hospital             0.000000\n",
      "admission_source_id          0.000000\n",
      "num_lab_procedures           0.000000\n",
      "encounter_id                 0.000000\n",
      "admission_type_id            0.000000\n",
      "discharge_disposition_id     0.000000\n",
      "gender                       0.000000\n",
      "age                          0.000000\n",
      "number_inpatient             0.000000\n",
      "number_emergency             0.000000\n",
      "number_outpatient            0.000000\n",
      "num_medications              0.000000\n",
      "num_procedures               0.000000\n",
      "number_diagnoses             0.000000\n",
      "metformin                    0.000000\n",
      "repaglinide                  0.000000\n",
      "nateglinide                  0.000000\n",
      "chlorpropamide               0.000000\n",
      "glimepiride                  0.000000\n",
      "acetohexamide                0.000000\n",
      "glipizide                    0.000000\n",
      "glyburide                    0.000000\n",
      "tolbutamide                  0.000000\n",
      "pioglitazone                 0.000000\n",
      "rosiglitazone                0.000000\n",
      "acarbose                     0.000000\n",
      "miglitol                     0.000000\n",
      "troglitazone                 0.000000\n",
      "tolazamide                   0.000000\n",
      "examide                      0.000000\n",
      "citoglipton                  0.000000\n",
      "insulin                      0.000000\n",
      "glyburide-metformin          0.000000\n",
      "glipizide-metformin          0.000000\n",
      "glimepiride-pioglitazone     0.000000\n",
      "metformin-rosiglitazone      0.000000\n",
      "metformin-pioglitazone       0.000000\n",
      "change                       0.000000\n",
      "diabetesMed                  0.000000\n",
      "readmitted                   0.000000\n",
      "dtype: float64\n",
      "\n",
      "Shape of dataframe after dropping sparse columns: (101766, 47)\n"
     ]
    }
   ],
   "source": [
    "# Replace '?' with NaN (Not a Number)\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentage = df.isnull().sum() * 100 / len(df)\n",
    "print(\"Percentage of missing values in each column:\")\n",
    "print(missing_percentage.sort_values(ascending=False))\n",
    "\n",
    "# Drop columns with a high percentage of missing values (e.g., > 40%)\n",
    "# 'weight', 'medical_specialty', and 'payer_code' are common candidates\n",
    "df.drop(['weight', 'payer_code', 'medical_specialty'], axis=1, inplace=True)\n",
    "\n",
    "print(\"\\nShape of dataframe after dropping sparse columns:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d351164-ef71-4aee-93ca-72c065d09a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value counts for 'readmitted':\n",
      "readmitted\n",
      "NO     54864\n",
      ">30    35545\n",
      "<30    11357\n",
      "Name: count, dtype: int64\n",
      "\n",
      "New value counts for 'readmitted':\n",
      "readmitted\n",
      "0    90409\n",
      "1    11357\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brenda\\AppData\\Local\\Temp\\ipykernel_12004\\1635786015.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['readmitted'] = df['readmitted'].replace({'<30': 1, '>30': 0, 'NO': 0})\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the 'readmitted' column\n",
    "print(\"Original value counts for 'readmitted':\")\n",
    "print(df['readmitted'].value_counts())\n",
    "\n",
    "# Map the values to a binary outcome\n",
    "# '<30' means the patient was readmitted within 30 days (our positive class, 1)\n",
    "# '>30' and 'NO' mean the patient was not readmitted within 30 days (our negative class, 0)\n",
    "df['readmitted'] = df['readmitted'].replace({'<30': 1, '>30': 0, 'NO': 0})\n",
    "\n",
    "# Verify the changes\n",
    "print(\"\\nNew value counts for 'readmitted':\")\n",
    "print(df['readmitted'].value_counts())\n",
    "\n",
    "# Notice the class imbalance: far more 0s than 1s. We will handle this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a67765d-5b20-4c11-84db-52b4606f4753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping duplicates: (101766, 47)\n",
      "Shape after dropping duplicates: (71518, 47)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape before dropping duplicates: {df.shape}\")\n",
    "\n",
    "# The 'patient_nbr' column identifies unique patients\n",
    "df.drop_duplicates(subset=['patient_nbr'], keep='first', inplace=True)\n",
    "\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462d8582-60eb-409e-842c-1a2f9871c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'gender':\n",
      "gender\n",
      "Female             38025\n",
      "Male               33490\n",
      "Unknown/Invalid        3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shape after removing 'Unknown/Invalid' gender: (71515, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brenda\\AppData\\Local\\Temp\\ipykernel_12004\\1004529840.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop encounter_id and patient_nbr as they are just identifiers and not useful features for prediction\n",
    "df.drop(['encounter_id', 'patient_nbr'], axis=1, inplace=True)\n",
    "\n",
    "# The 'diag' columns have thousands of unique codes (ICD-9).\n",
    "# A simple feature engineering approach is to group them by broader categories.\n",
    "# For now, let's just check for missing values in them (which might be represented by NaN after our earlier step)\n",
    "# A common strategy for the few remaining NaNs is to fill with the mode (most frequent value).\n",
    "for col in ['race', 'diag_1', 'diag_2', 'diag_3']:\n",
    "    if df[col].isnull().any():\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Let's check if 'gender' has any non-binary values that need cleaning\n",
    "print(\"\\nValue counts for 'gender':\")\n",
    "print(df['gender'].value_counts())\n",
    "\n",
    "# There's a small number of 'Unknown/Invalid' values. Let's remove these rows.\n",
    "df = df[df['gender'] != 'Unknown/Invalid']\n",
    "print(\"\\nShape after removing 'Unknown/Invalid' gender:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a679dba-befb-49e2-8854-d71b4f51bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for diag_1 after grouping:\n",
      "diag_1\n",
      "Other              38296\n",
      "Respiratory         8349\n",
      "Digestive           6570\n",
      "Diabetes            5805\n",
      "Injury              5107\n",
      "Musculoskeletal     4080\n",
      "Neoplasms           2057\n",
      "Genitourinary       1070\n",
      "Circulatory          181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Grouping diagnosis codes into broader categories\n",
    "# Based on ICD-9 code ranges\n",
    "\n",
    "def map_diag_codes(df_col):\n",
    "    # Neoplasms\n",
    "    if df_col.startswith('1') and 140 <= float(df_col) < 240: return 'Neoplasms'\n",
    "    # Diabetes\n",
    "    if df_col.startswith('250'): return 'Diabetes'\n",
    "    # Circulatory\n",
    "    if (df_col.startswith('39') and 390 <= float(df_col) < 460) or (df_col.startswith('785')): return 'Circulatory'\n",
    "    # Respiratory\n",
    "    if (df_col.startswith('4') and 460 <= float(df_col) < 520) or (df_col.startswith('786')): return 'Respiratory'\n",
    "    # Digestive\n",
    "    if (df_col.startswith('5') and 520 <= float(df_col) < 580) or (df_col.startswith('787')): return 'Digestive'\n",
    "    # Genitourinary\n",
    "    if (df_col.startswith('58') and 580 <= float(df_col) < 630) or (df_col.startswith('788')): return 'Genitourinary'\n",
    "    # Musculoskeletal\n",
    "    if df_col.startswith('710') or (df_col.startswith('7') and 710 <= float(df_col) < 740): return 'Musculoskeletal'\n",
    "    # Injury\n",
    "    if df_col.startswith('8') or df_col.startswith('9'): return 'Injury'\n",
    "    # Other\n",
    "    return 'Other'\n",
    "\n",
    "# Apply the mapping function to the diagnosis columns\n",
    "# We must first ensure the columns are strings\n",
    "df['diag_1'] = df['diag_1'].astype(str).apply(map_diag_codes)\n",
    "df['diag_2'] = df['diag_2'].astype(str).apply(map_diag_codes)\n",
    "df['diag_3'] = df['diag_3'].astype(str).apply(map_diag_codes)\n",
    "\n",
    "# Let's check the new value counts\n",
    "print(\"Value counts for diag_1 after grouping:\")\n",
    "print(df['diag_1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c961740-b701-4ec4-a334-8f2235f1eefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of the new 'num_medications' feature:\n",
      "count    71515.000000\n",
      "mean         1.182703\n",
      "std          0.940275\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          2.000000\n",
      "max          6.000000\n",
      "Name: num_medications, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# List of medication columns\n",
    "med_cols = [\n",
    "    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "    'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
    "    'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',\n",
    "    'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
    "    'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone'\n",
    "]\n",
    "\n",
    "# Create a feature for the number of medications prescribed\n",
    "# 'No' means not prescribed. Any other value ('Up', 'Down', 'Steady') means it is.\n",
    "df['num_medications'] = (df[med_cols] != 'No').sum(axis=1)\n",
    "\n",
    "print(\"Description of the new 'num_medications' feature:\")\n",
    "print(df['num_medications'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09638cd3-1ec2-4ad3-928a-a332562255f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns to be encoded: ['race', 'gender', 'age', 'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed']\n",
      "\n",
      "Shape of dataframe after one-hot encoding: (71515, 101)\n",
      "A few of the new columns: ['glipizide-metformin_Steady', 'metformin-rosiglitazone_Steady', 'metformin-pioglitazone_Steady', 'change_No', 'diabetesMed_Yes']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "print(f\"Categorical columns to be encoded: {list(categorical_cols)}\")\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(\"\\nShape of dataframe after one-hot encoding:\", df_encoded.shape)\n",
    "print(\"A few of the new columns:\", list(df_encoded.columns[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d897fcb-c8e0-461a-88f7-2755668ef4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (57212, 100)\n",
      "Testing set shape: (14303, 100)\n",
      "\n",
      "Readmission rate in training set:\n",
      "readmitted\n",
      "0    0.912011\n",
      "1    0.087989\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Readmission rate in testing set:\n",
      "readmitted\n",
      "0    0.911977\n",
      "1    0.088023\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_encoded.drop('readmitted', axis=1)\n",
    "y = df_encoded['readmitted']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"\\nReadmission rate in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nReadmission rate in testing set:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56e2f615-ea66-40a6-9c5f-cf5e706160ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts before SMOTE:\n",
      "readmitted\n",
      "0    52178\n",
      "1     5034\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts after SMOTE:\n",
      "readmitted\n",
      "1    52178\n",
      "0    52178\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# IMPORTANT: Apply SMOTE only to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Value counts before SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nValue counts after SMOTE:\")\n",
    "print(y_train_smote.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ad09ac9-7a6e-492d-a14e-ad4845015a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of scaled training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>num_medications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.572186</td>\n",
       "      <td>0.469472</td>\n",
       "      <td>-0.767333</td>\n",
       "      <td>-0.234348</td>\n",
       "      <td>-0.182694</td>\n",
       "      <td>-0.281371</td>\n",
       "      <td>0.892367</td>\n",
       "      <td>-0.062106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.914559</td>\n",
       "      <td>-0.240866</td>\n",
       "      <td>-0.168093</td>\n",
       "      <td>-0.234348</td>\n",
       "      <td>-0.182694</td>\n",
       "      <td>-0.281371</td>\n",
       "      <td>0.892367</td>\n",
       "      <td>-0.062106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112562</td>\n",
       "      <td>0.367996</td>\n",
       "      <td>-0.767333</td>\n",
       "      <td>-0.234348</td>\n",
       "      <td>6.623867</td>\n",
       "      <td>1.300842</td>\n",
       "      <td>0.892367</td>\n",
       "      <td>-0.062106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.112562</td>\n",
       "      <td>-0.291604</td>\n",
       "      <td>-0.168093</td>\n",
       "      <td>-0.234348</td>\n",
       "      <td>-0.182694</td>\n",
       "      <td>-0.281371</td>\n",
       "      <td>-1.196279</td>\n",
       "      <td>-0.062106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.599307</td>\n",
       "      <td>-1.458588</td>\n",
       "      <td>-0.168093</td>\n",
       "      <td>-0.234348</td>\n",
       "      <td>-0.182694</td>\n",
       "      <td>-0.281371</td>\n",
       "      <td>0.892367</td>\n",
       "      <td>1.094199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_in_hospital  num_lab_procedures  num_procedures  number_outpatient  \\\n",
       "0          0.572186            0.469472       -0.767333          -0.234348   \n",
       "1          0.914559           -0.240866       -0.168093          -0.234348   \n",
       "2         -0.112562            0.367996       -0.767333          -0.234348   \n",
       "3         -0.112562           -0.291604       -0.168093          -0.234348   \n",
       "4          1.599307           -1.458588       -0.168093          -0.234348   \n",
       "\n",
       "   number_emergency  number_inpatient  number_diagnoses  num_medications  \n",
       "0         -0.182694         -0.281371          0.892367        -0.062106  \n",
       "1         -0.182694         -0.281371          0.892367        -0.062106  \n",
       "2          6.623867          1.300842          0.892367        -0.062106  \n",
       "3         -0.182694         -0.281371         -1.196279        -0.062106  \n",
       "4         -0.182694         -0.281371          0.892367         1.094199  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We need to scale only the original numerical columns\n",
    "# The one-hot encoded columns are already on a 0/1 scale\n",
    "cols_to_scale = [\n",
    "    'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    "    'number_outpatient', 'number_emergency', 'number_inpatient',\n",
    "    'number_diagnoses', 'num_medications'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler ONLY on the training data\n",
    "X_train_smote[cols_to_scale] = scaler.fit_transform(X_train_smote[cols_to_scale])\n",
    "\n",
    "# Transform the test data using the SAME scaler fitted on the training data\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "\n",
    "print(\"\\nFirst 5 rows of scaled training data:\")\n",
    "display(X_train_smote[cols_to_scale].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d24a26-e51f-4a80-bc1d-de9e10986a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Done.\n",
      "\n",
      "Training Random Forest...\n",
      "Done.\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names must be string, and may not contain [, ] or <",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining XGBoost...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_smote\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_smote\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1664\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1659\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mnum_class\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.n_classes_\n\u001b[32m   1661\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1662\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1663\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1664\u001b[39m train_dmatrix, evals = \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1670\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1673\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1674\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1677\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1681\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = train(\n\u001b[32m   1684\u001b[39m     params,\n\u001b[32m   1685\u001b[39m     train_dmatrix,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1694\u001b[39m     callbacks=\u001b[38;5;28mself\u001b[39m.callbacks,\n\u001b[32m   1695\u001b[39m )\n\u001b[32m   1697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:628\u001b[39m, in \u001b[36m_wrap_evaluation_matrices\u001b[39m\u001b[34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap_evaluation_matrices\u001b[39m(\n\u001b[32m    608\u001b[39m     *,\n\u001b[32m    609\u001b[39m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m     feature_types: Optional[FeatureTypes],\n\u001b[32m    625\u001b[39m ) -> Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m    626\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[33;03m    way.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m     train_dmatrix = \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m     n_validation = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[32m    644\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) -> Sequence:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1137\u001b[39m, in \u001b[36mXGBModel._create_dmatrix\u001b[39m\u001b[34m(self, ref, **kwargs)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m.tree_method, \u001b[38;5;28mself\u001b[39m.device) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.booster != \u001b[33m\"\u001b[39m\u001b[33mgblinear\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_bin\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:1614\u001b[39m, in \u001b[36mQuantileDMatrix.__init__\u001b[39m\u001b[34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, max_quantile_batches, data_split_mode)\u001b[39m\n\u001b[32m   1594\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1595\u001b[39m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1607\u001b[39m         )\n\u001b[32m   1608\u001b[39m     ):\n\u001b[32m   1609\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1610\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf data iterator is used as input, data like label should be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1611\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mspecified as batch argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1612\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_quantile_blocks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_quantile_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:1678\u001b[39m, in \u001b[36mQuantileDMatrix._init\u001b[39m\u001b[34m(self, data, ref, enable_categorical, max_quantile_blocks, **meta)\u001b[39m\n\u001b[32m   1663\u001b[39m config = make_jcargs(\n\u001b[32m   1664\u001b[39m     nthread=\u001b[38;5;28mself\u001b[39m.nthread,\n\u001b[32m   1665\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1666\u001b[39m     max_bin=\u001b[38;5;28mself\u001b[39m.max_bin,\n\u001b[32m   1667\u001b[39m     max_quantile_blocks=max_quantile_blocks,\n\u001b[32m   1668\u001b[39m )\n\u001b[32m   1669\u001b[39m ret = _LIB.XGQuantileDMatrixCreateFromCallback(\n\u001b[32m   1670\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1671\u001b[39m     it.proxy.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1676\u001b[39m     ctypes.byref(handle),\n\u001b[32m   1677\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1678\u001b[39m \u001b[43mit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[32m   1680\u001b[39m _check_call(ret)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:572\u001b[39m, in \u001b[36mDataIter.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    570\u001b[39m exc = \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    571\u001b[39m \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:553\u001b[39m, in \u001b[36mDataIter._handle_exception\u001b[39m\u001b[34m(self, fn, dft_ret)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    555\u001b[39m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[32m    556\u001b[39m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[32m    557\u001b[39m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[32m    558\u001b[39m     tb = sys.exc_info()[\u001b[32m2\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:640\u001b[39m, in \u001b[36mDataIter._next_wrapper.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28mself\u001b[39m._temporary_data = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m), \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:1654\u001b[39m, in \u001b[36mSingleBatchInternalIter.next\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m   1652\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28mself\u001b[39m.it += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1654\u001b[39m \u001b[43minput_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1655\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:629\u001b[39m, in \u001b[36mDataIter._next_wrapper.<locals>.input_data\u001b[39m\u001b[34m(data, feature_names, feature_types, **kwargs)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;28mself\u001b[39m._temporary_data = (new, cat_codes, feature_names, feature_types)\n\u001b[32m    628\u001b[39m dispatch_proxy_set_data(\u001b[38;5;28mself\u001b[39m.proxy, new, cat_codes)\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[38;5;28mself\u001b[39m._data_ref = ref\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:975\u001b[39m, in \u001b[36mDMatrix.set_info\u001b[39m\u001b[34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[39m\n\u001b[32m    973\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_float_info(\u001b[33m\"\u001b[39m\u001b[33mlabel_upper_bound\u001b[39m\u001b[33m\"\u001b[39m, label_upper_bound)\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m975\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_names\u001b[49m = feature_names\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    977\u001b[39m     \u001b[38;5;28mself\u001b[39m.feature_types = feature_types\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:1364\u001b[39m, in \u001b[36mDMatrix.feature_names\u001b[39m\u001b[34m(self, feature_names)\u001b[39m\n\u001b[32m   1359\u001b[39m \u001b[38;5;66;03m# prohibit the use symbols that may affect parsing. e.g. []<\u001b[39;00m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m<\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feature_names\n\u001b[32m   1363\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1364\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1365\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfeature_names must be string, and may not contain [, ] or <\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1366\u001b[39m     )\n\u001b[32m   1368\u001b[39m feature_names_bytes = [\u001b[38;5;28mbytes\u001b[39m(f, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feature_names]\n\u001b[32m   1369\u001b[39m c_feature_names = (ctypes.c_char_p * \u001b[38;5;28mlen\u001b[39m(feature_names_bytes))(\n\u001b[32m   1370\u001b[39m     *feature_names_bytes\n\u001b[32m   1371\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: feature_names must be string, and may not contain [, ] or <"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize the models\n",
    "# We use class_weight='balanced' for models that support it as an extra measure\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "rand_forest = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train the models on the SMOTE-resampled training data\n",
    "print(\"Training Logistic Regression...\")\n",
    "log_reg.fit(X_train_smote, y_train_smote)\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rand_forest.fit(X_train_smote, y_train_smote)\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb.fit(X_train_smote, y_train_smote)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "658ed7d7-90d7-4612-90e6-a5b90524c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Done.\n",
      "\n",
      "Training Random Forest...\n",
      "Done.\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brenda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:41:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- FIX STARTS HERE ---\n",
    "# The error is from special characters XGBoost can't handle. Let's clean them.\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "# Clean the column names for the training set\n",
    "X_train_smote.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train_smote.columns.values]\n",
    "\n",
    "# IMPORTANT: Apply the exact same column name changes to the test set\n",
    "X_test.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_test.columns.values]\n",
    "# --- FIX ENDS HERE ---\n",
    "\n",
    "\n",
    "# Initialize the models\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "rand_forest = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "# Note: use_label_encoder=False is deprecated and will be removed.\n",
    "# We set it explicitly to avoid a warning. eval_metric silences another warning.\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "\n",
    "# Train the models on the SMOTE-resampled training data\n",
    "print(\"Training Logistic Regression...\")\n",
    "log_reg.fit(X_train_smote, y_train_smote)\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rand_forest.fit(X_train_smote, y_train_smote)\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb.fit(X_train_smote, y_train_smote)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013ec68-c48b-4bc5-a376-fdda8412d663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
